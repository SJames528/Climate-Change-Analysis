---
output: git_document
---


```{r, echo = FALSE}
knitr::opts_chunk$set(fig.path = "Figures/EDA/EDA-")
```

## Climate Change Analysis

### Set Preliminaries

```{r}
library(ggplot2)
data_loc="~/Projects/Data/Climate-Change-Analysis"
```

### Load in Data

```{r}
city_data <- read.csv(paste(data_loc, "/GlobalLandTemperaturesByCity.csv", sep = ""))
city_data$dt <- as.Date(city_data$dt, "%Y-%m-%d")
head(city_data)
```

### EDA

There are records for several thousand cities here, each with regular monthly average temperature and uncertainty readings. It will be easier to focus on one city to begin with.

```{r}
minsk_data_init <- city_data[city_data[,"City"]=="Minsk",]
head(minsk_data_init)
```

There are already visible entries with missing data

```{r}
minsk_data_missing = minsk_data_init[is.na(minsk_data_init[,"AverageTemperature"]) | is.na(minsk_data_init[,"AverageTemperatureUncertainty"]),]
dim(minsk_data_missing)
```

Luckily, however, only 73 entries contain missing temperature data. This should be
a small enough proportion of the entries to continue our analysis without needing to
deal with data cleaning.

```{r, echo=FALSE}
print("Missing Dates:")
minsk_data_missing$dt
```
We can see here that the data is complete from around 1753 onwards, with the exception of one month in 2013. The easiest way around this is to remove all entries from before 1753, and ignore the single instance in 2013.

```{r}
minsk_data = minsk_data_init[format(minsk_data_init$dt, format="%Y")>=1753,]
minsk_data = minsk_data[!(is.na(minsk_data[,"AverageTemperature"]) | is.na(minsk_data[,"AverageTemperatureUncertainty"])),]
summary(minsk_data)
```


We can create some plots to observe initial trends in the data

```{r}
plot(minsk_data[, c("dt","AverageTemperature")],type="l",main="Average Temperature in Minsk")
plot(minsk_data[, c("dt","AverageTemperatureUncertainty")],type="l",main="Uncertainty of Average Temperature Reading in Minsk")
```
The average temperature reading data follows a regular variation, as would be
expected throughtout the year. An appropriate next step may be to isolate readings
for each month of the year or seasonally, in order to better see trends across time.

The uncertainty data tells us that early readings for temperature are wildly more
uncertain than those taken in the last century or so.

```{r}
seasonal_months <- c("Jan", "Apr", "Jul", "Oct")
minsk_data_snl <- list()
for (mon in seasonal_months){
    minsk_data_snl[[mon]] <- minsk_data[format(minsk_data$dt, format="%b") == mon,]
}
```
Plot seasonal data, which will make the data easier to model and test:

```{r}
seasonal_plot <- ggplot()
colours = c("#000080","#d40202","#d9d400", "#008000")
for (i in 1:4){
    seasonal_plot <- seasonal_plot + geom_line(data = minsk_data_snl[[i]], aes(x = dt, y = AverageTemperature), color = colours[i], alpha = 0.7)
}
seasonal_plot + theme_minimal()
```

<p>There are no visible trends in the data, as yearly variance causes interference.
However, it is possible we can statistically test for a significant increase over
time, which would indicate provable evidence of global warming.</p>


### Statistical Testing

<p>I will first try a basic test, asking if the yearly difference sequence has a mean greater than zero, which would certainly imply increase in temperature over time. I will be using a significance level of \alpha = 0.05. I will perform this test on each month in turn, thus obtaining 12 complete tests for each location.</p>

<p>Some alternative methods include the following:
* Define a suitable year range (e.g. 1750-1900) as a "control" period, and testing if recent measurements fit within the control temperature distribution.
* Take only the yearly highest temperatures, and perform the difference sequence test.

#### Difference Sequence Generation

First, obtain seperate data for each month and then convert the absolute data into yearly differences:

```{r}
months <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
minsk_data_monthly <- list()
minsk_data_month_diff <- list()
for (mon in months){
  minsk_data_monthly[[mon]] <- minsk_data[format(minsk_data$dt, format="%b") == mon,]
}
head(minsk_data_monthly[["Jan"]])
```

```{r}
for (mon in months){
  minsk_data_month_diff[[mon]] <- data.frame(minsk_data_monthly[[mon]]$dt[-1])
  names(minsk_data_month_diff[[mon]]) = c("Date")
  minsk_data_month_diff[[mon]]["Difference"] <- minsk_data_monthly[[mon]]$AverageTemperature[-1] - minsk_data_monthly[[mon]]$AverageTemperature[-(dim(minsk_data_monthly[[mon]])[1])]
  minsk_data_month_diff[[mon]]["DifferenceUncertainty"] <- minsk_data_monthly[[mon]]$AverageTemperatureUncertainty[-1] + minsk_data_monthly[[mon]]$AverageTemperatureUncertainty[-(dim(minsk_data_monthly[[mon]])[1])]
}
head(minsk_data_month_diff[["Jan"]])
```
We can visualise this transformation of the data:

```{r}
ggplot() + geom_point(data = minsk_data_month_diff[["Jan"]], aes(x = Date, y = Difference), alpha = 0.7) + ggtitle("Year-to-Year changes in January temperature in Minsk") + xlab("Year") + ylab("Temperature Difference (Celcius)")
ggplot() + geom_line(data = minsk_data_month_diff[["Jan"]], aes(x = Date, y = DifferenceUncertainty), alpha = 0.7)
```

We need to bear uncertainty in mind, since the error in this data is quite significant. By taking the difference between two seperate measurements, we combine the error, which means the difference scores for earlier years are particularly uncertain, and this may cast doubt on any conclusions we make. Here we can see a portion of the difference sequence with uncertainty included:

```{r}
minsk_jan_reduced=minsk_data_month_diff[["Jan"]][c(50:100),]
ggplot(minsk_jan_reduced) + geom_point(aes(x = Date, y = Difference))  + geom_errorbar(aes(x = Date, y = Difference, ymin=Difference-DifferenceUncertainty, ymax=Difference+DifferenceUncertainty))
```

#### Hypothesis Testing

Now that we have our transformed difference sequence (X_1_,X_2_,...,X_N_), I will divide by the empirical standard deviation and test the following hypothesis.

* H_0_: X_1_,...,X_N_ ~ i.i.d normal(0,1)
* H_1_: X_1_,...,X_N_ ~ i.i.d normal(\mu,1)   where \mu > 0

We want our test statistic here to be the most powerful possible (smallest type II error rate), which by the Neyman-Pearson Lemma is equivelant the mean of the difference sequence. For a proof of this, please see Section A in the appendix. I will gather a p-value for each month of the year, to gain 12 scores in total.

```{r}
for (mon in months){
    minsk_data_month_diff[[mon]]["StandardisedDifference"] = minsk_data_month_diff[[mon]]$Difference / sd(minsk_data_month_diff[[mon]]$Difference)
}
head(minsk_data_month_diff[["Jan"]])
```
With our standardised sequence, we can now proceed:
```{r}
p_values <- data.frame(Location=character(), JanPVal=integer(), FebPVal=integer(), MarPVal=integer(), AprPVal=integer(), MayPVal=integer(), JunPVal=integer(), JulPVal=integer(), AugPVal=integer(), SepPVal=integer(), OctPVal=integer(), NovPVal=integer(), DecPVal=integer(), stringsAsFactors = FALSE)
pval_calculator_minsk <- function(mon){
    diff_mean=mean(minsk_data_month_diff[[mon]]$StandardisedDifference)
    diff_data_length=dim(minsk_data_month_diff[[mon]])[1]
    return(1-pnorm(sqrt(diff_data_length)*diff_mean,0,1))
}
p_values[1,]=append(c("Minsk"),sapply(months,pval_calculator_minsk))
p_values
```
